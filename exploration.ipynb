{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA Data Tenis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julián Pérez\\AppData\\Local\\Temp\\ipykernel_9496\\1341552323.py:5: DtypeWarning: Columns (36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n"
     ]
    }
   ],
   "source": [
    "### --------------\n",
    "# Cargando el dataset y generando un reporte de los datos automático con YData profiling\n",
    "data_path = os.path.join(os.getcwd(), \"data\", \"tennis_data.csv\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "#profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "\n",
    "#profile.to_file(\"your_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Location\", \"Date\", \"Series\", \"Court\", \"Surface\", \"Best of\", \"Winner\", \"Loser\", \"WRank\", \"LRank\", \"WPts\", \"LPts\", \"pl1_flag\", \"pl1_year_pro\", \"pl1_weight\", \"pl1_height\", \"pl1_hand\", \"pl2_flag\", \"pl2_year_pro\", \"pl2_weight\", \"pl2_height\", \"pl2_hand\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Best of</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Loser</th>\n",
       "      <th>WRank</th>\n",
       "      <th>LRank</th>\n",
       "      <th>...</th>\n",
       "      <th>pl1_flag</th>\n",
       "      <th>pl1_year_pro</th>\n",
       "      <th>pl1_weight</th>\n",
       "      <th>pl1_height</th>\n",
       "      <th>pl1_hand</th>\n",
       "      <th>pl2_flag</th>\n",
       "      <th>pl2_year_pro</th>\n",
       "      <th>pl2_weight</th>\n",
       "      <th>pl2_height</th>\n",
       "      <th>pl2_hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>ATP250</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>Kwon S.W.</td>\n",
       "      <td>Nishioka Y.</td>\n",
       "      <td>53.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>KOR</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>JPN</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Left-Handed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>ATP250</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>Monteiro T.</td>\n",
       "      <td>Altmaier D.</td>\n",
       "      <td>89.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>BRA</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>Left-Handed</td>\n",
       "      <td>GER</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>ATP250</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>Djere L.</td>\n",
       "      <td>Carballes Baena R.</td>\n",
       "      <td>52.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SRB</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>ESP</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>ATP250</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson S.</td>\n",
       "      <td>Vukic A.</td>\n",
       "      <td>85.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>AUS</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelaide</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>ATP250</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>Moutet C.</td>\n",
       "      <td>Rune H.</td>\n",
       "      <td>92.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>Left-Handed</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location        Date  Series    Court Surface  Best of       Winner  \\\n",
       "0  Adelaide  2022-01-03  ATP250  Outdoor    Hard        3    Kwon S.W.   \n",
       "1  Adelaide  2022-01-03  ATP250  Outdoor    Hard        3  Monteiro T.   \n",
       "2  Adelaide  2022-01-03  ATP250  Outdoor    Hard        3     Djere L.   \n",
       "3  Adelaide  2022-01-03  ATP250  Outdoor    Hard        3   Johnson S.   \n",
       "4  Adelaide  2022-01-04  ATP250  Outdoor    Hard        3    Moutet C.   \n",
       "\n",
       "                Loser  WRank  LRank  ...  pl1_flag  pl1_year_pro pl1_weight  \\\n",
       "0         Nishioka Y.   53.0   81.0  ...       KOR        2015.0       72.0   \n",
       "1         Altmaier D.   89.0   84.0  ...       BRA        2011.0       78.0   \n",
       "2  Carballes Baena R.   52.0   79.0  ...       SRB        2013.0       80.0   \n",
       "3            Vukic A.   85.0  156.0  ...       USA        2012.0       86.0   \n",
       "4             Rune H.   92.0  103.0  ...       FRA        2016.0       71.0   \n",
       "\n",
       "   pl1_height      pl1_hand  pl2_flag pl2_year_pro pl2_weight  pl2_height  \\\n",
       "0       180.0  Right-Handed       JPN       2014.0       64.0       170.0   \n",
       "1       183.0   Left-Handed       GER       2014.0       80.0       188.0   \n",
       "2       185.0  Right-Handed       ESP       2011.0       76.0       180.0   \n",
       "3       188.0  Right-Handed       AUS       2018.0       85.0       188.0   \n",
       "4       175.0   Left-Handed       DEN       2020.0       77.0       188.0   \n",
       "\n",
       "       pl2_hand  \n",
       "0   Left-Handed  \n",
       "1  Right-Handed  \n",
       "2  Right-Handed  \n",
       "3  Right-Handed  \n",
       "4  Right-Handed  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busqueda de atipicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### quitando alturas atípicas\n",
    "df = df[~((df[\"pl1_height\"] > 220) |  (df[\"pl1_height\"] < 150) | (df[\"pl2_height\"] > 220) |  (df[\"pl2_height\"] < 150))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Quitando pesos atípicos\n",
    "df = df[~((df[\"pl1_weight\"] > 120) |  (df[\"pl1_weight\"] < 50) | (df[\"pl2_weight\"] > 120) |  (df[\"pl2_weight\"] < 50))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Quitando las fechas de pro atipicas\n",
    "df = df[~((df[\"pl1_year_pro\"] > 2023) |  (df[\"pl1_year_pro\"] < 1980) | (df[\"pl2_year_pro\"] > 2023) |  (df[\"pl2_year_pro\"] < 1980))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year_match\"] = pd.to_datetime(df[\"Date\"]).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Obtener columna que indica cuantos años lleva siendo profesional el tenista\n",
    "df[\"pl1_professional_time\"] = df[\"year_match\"] - df[\"pl1_year_pro\"]\n",
    "df[\"pl2_professional_time\"] = df[\"year_match\"] - df[\"pl2_year_pro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_random_values = np.random.randint(0, 2, size=35277)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"random_distribution_winner\"] = pd_random_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winners = df[df[\"random_distribution_winner\"] == 1]\n",
    "df_losers = df[df[\"random_distribution_winner\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Location', 'Date', 'Series', 'Court', 'Surface', 'Best of', 'Winner',\n",
       "       'Loser', 'WRank', 'LRank', 'WPts', 'LPts', 'pl1_flag', 'pl1_year_pro',\n",
       "       'pl1_weight', 'pl1_height', 'pl1_hand', 'pl2_flag', 'pl2_year_pro',\n",
       "       'pl2_weight', 'pl2_height', 'pl2_hand', 'year_match',\n",
       "       'pl1_professional_time', 'pl2_professional_time',\n",
       "       'random_distribution_winner'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_winners.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players_1 = pd.DataFrame()\n",
    "\n",
    "df_players_1[\"pl1\"] = df_winners[\"Winner\"]\n",
    "df_players_1[\"pl1_pts\"] = df_winners[\"WPts\"]\n",
    "df_players_1[\"pl1_flag\"] = df_winners[\"pl1_flag\"]\n",
    "df_players_1[\"pl1_weight\"] = df_winners[\"pl1_weight\"]\n",
    "df_players_1[\"pl1_height\"] = df_winners[\"pl1_height\"]\n",
    "df_players_1[\"pl1_hand\"] = df_winners[\"pl1_hand\"]\n",
    "df_players_1[\"pl1_professional_time\"] = df_winners[\"pl1_professional_time\"]\n",
    "df_players_1[\"pl2\"] = df_winners[\"Loser\"]\n",
    "df_players_1[\"pl2_pts\"] = df_winners[\"LPts\"]\n",
    "df_players_1[\"pl2_flag\"] = df_winners[\"pl2_flag\"]\n",
    "df_players_1[\"pl2_weight\"] = df_winners[\"pl2_weight\"]\n",
    "df_players_1[\"pl2_height\"] = df_winners[\"pl2_height\"]\n",
    "df_players_1[\"pl2_hand\"] = df_winners[\"pl2_hand\"]\n",
    "df_players_1[\"pl2_professional_time\"] = df_winners[\"pl2_professional_time\"]\n",
    "df_players_1[\"location\"] = df_winners[\"Location\"]\n",
    "df_players_1[\"series\"] = df_winners[\"Series\"]\n",
    "df_players_1[\"court\"] = df_winners[\"Court\"]\n",
    "df_players_1[\"surface\"] = df_winners[\"Surface\"]\n",
    "df_players_1[\"best_of\"] = df_winners[\"Best of\"]\n",
    "df_players_1[\"winner\"] = \"p1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players_2 = pd.DataFrame()\n",
    "\n",
    "df_players_2[\"pl1\"] = df_losers[\"Loser\"]\n",
    "df_players_2[\"pl1_pts\"] = df_losers[\"LPts\"]\n",
    "df_players_2[\"pl1_flag\"] = df_losers[\"pl2_flag\"]\n",
    "df_players_2[\"pl1_weight\"] = df_losers[\"pl2_weight\"]\n",
    "df_players_2[\"pl1_height\"] = df_losers[\"pl2_height\"]\n",
    "df_players_2[\"pl1_hand\"] = df_losers[\"pl2_hand\"]\n",
    "df_players_2[\"pl1_professional_time\"] = df_losers[\"pl2_professional_time\"]\n",
    "df_players_2[\"pl2\"] = df_losers[\"Winner\"]\n",
    "df_players_2[\"pl2_pts\"] = df_losers[\"WPts\"]\n",
    "df_players_2[\"pl2_flag\"] = df_losers[\"pl1_flag\"]\n",
    "df_players_2[\"pl2_weight\"] = df_losers[\"pl1_weight\"]\n",
    "df_players_2[\"pl2_height\"] = df_losers[\"pl1_height\"]\n",
    "df_players_2[\"pl2_hand\"] = df_losers[\"pl1_hand\"]\n",
    "df_players_2[\"pl2_professional_time\"] = df_losers[\"pl1_professional_time\"]\n",
    "df_players_2[\"location\"] = df_losers[\"Location\"]\n",
    "df_players_2[\"series\"] = df_losers[\"Series\"]\n",
    "df_players_2[\"court\"] = df_losers[\"Court\"]\n",
    "df_players_2[\"surface\"] = df_losers[\"Surface\"]\n",
    "df_players_2[\"best_of\"] = df_losers[\"Best of\"]\n",
    "df_players_2[\"winner\"] = \"p2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_players = pd.concat([df_players_1, df_players_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_players = df_all_players.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pl1</th>\n",
       "      <th>pl1_pts</th>\n",
       "      <th>pl1_flag</th>\n",
       "      <th>pl1_weight</th>\n",
       "      <th>pl1_height</th>\n",
       "      <th>pl1_hand</th>\n",
       "      <th>pl1_professional_time</th>\n",
       "      <th>pl2</th>\n",
       "      <th>pl2_pts</th>\n",
       "      <th>pl2_flag</th>\n",
       "      <th>pl2_weight</th>\n",
       "      <th>pl2_height</th>\n",
       "      <th>pl2_hand</th>\n",
       "      <th>pl2_professional_time</th>\n",
       "      <th>location</th>\n",
       "      <th>series</th>\n",
       "      <th>court</th>\n",
       "      <th>surface</th>\n",
       "      <th>best_of</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gabashvili T.</td>\n",
       "      <td>339.0</td>\n",
       "      <td>RUS</td>\n",
       "      <td>83.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Simon G.</td>\n",
       "      <td>875.0</td>\n",
       "      <td>FRA</td>\n",
       "      <td>70.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>International Gold</td>\n",
       "      <td>Indoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>p2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stakhovsky S.</td>\n",
       "      <td>700.0</td>\n",
       "      <td>UKR</td>\n",
       "      <td>80.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Donskoy E.</td>\n",
       "      <td>371.0</td>\n",
       "      <td>RUS</td>\n",
       "      <td>74.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>ATP500</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Clay</td>\n",
       "      <td>3</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Federer R.</td>\n",
       "      <td>6620.0</td>\n",
       "      <td>SUI</td>\n",
       "      <td>85.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Clarke J.</td>\n",
       "      <td>316.0</td>\n",
       "      <td>GBR</td>\n",
       "      <td>83.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>3.0</td>\n",
       "      <td>London</td>\n",
       "      <td>Grand Slam</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Grass</td>\n",
       "      <td>5</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Giraldo S.</td>\n",
       "      <td>790.0</td>\n",
       "      <td>COL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Kudla D.</td>\n",
       "      <td>496.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>75.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>5.0</td>\n",
       "      <td>London</td>\n",
       "      <td>Grand Slam</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Grass</td>\n",
       "      <td>5</td>\n",
       "      <td>p2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lacko L.</td>\n",
       "      <td>691.0</td>\n",
       "      <td>SVK</td>\n",
       "      <td>85.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Serra F.</td>\n",
       "      <td>780.0</td>\n",
       "      <td>FRA</td>\n",
       "      <td>78.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>10.0</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>ATP250</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35272</th>\n",
       "      <td>Tsonga J.W.</td>\n",
       "      <td>245.0</td>\n",
       "      <td>FRA</td>\n",
       "      <td>91.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Simon G.</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>FRA</td>\n",
       "      <td>70.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Montpellier</td>\n",
       "      <td>ATP250</td>\n",
       "      <td>Indoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35273</th>\n",
       "      <td>Copil M.</td>\n",
       "      <td>597.0</td>\n",
       "      <td>ROU</td>\n",
       "      <td>86.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Bedene A.</td>\n",
       "      <td>815.0</td>\n",
       "      <td>GBR</td>\n",
       "      <td>72.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>10.0</td>\n",
       "      <td>'s-Hertogenbosch</td>\n",
       "      <td>ATP250</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Grass</td>\n",
       "      <td>3</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35274</th>\n",
       "      <td>Muller G.</td>\n",
       "      <td>1127.0</td>\n",
       "      <td>LUX</td>\n",
       "      <td>89.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Left-Handed</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Wawrinka S.</td>\n",
       "      <td>4050.0</td>\n",
       "      <td>SUI</td>\n",
       "      <td>81.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>ATP500</td>\n",
       "      <td>Indoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>p2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35275</th>\n",
       "      <td>Marchenko I.</td>\n",
       "      <td>305.0</td>\n",
       "      <td>UKR</td>\n",
       "      <td>82.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Matosevic M.</td>\n",
       "      <td>887.0</td>\n",
       "      <td>AUS</td>\n",
       "      <td>86.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>ATP500</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>p2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35276</th>\n",
       "      <td>Souza J.</td>\n",
       "      <td>554.0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>92.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Haider-Maurer A.</td>\n",
       "      <td>810.0</td>\n",
       "      <td>AUT</td>\n",
       "      <td>89.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>Right-Handed</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Kitzbuhel</td>\n",
       "      <td>ATP250</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Clay</td>\n",
       "      <td>3</td>\n",
       "      <td>p2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35277 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pl1  pl1_pts pl1_flag  pl1_weight  pl1_height      pl1_hand  \\\n",
       "0      Gabashvili T.    339.0      RUS        83.0       188.0  Right-Handed   \n",
       "1      Stakhovsky S.    700.0      UKR        80.0       193.0  Right-Handed   \n",
       "2         Federer R.   6620.0      SUI        85.0       185.0  Right-Handed   \n",
       "3         Giraldo S.    790.0      COL        75.0       188.0  Right-Handed   \n",
       "4           Lacko L.    691.0      SVK        85.0       185.0  Right-Handed   \n",
       "...              ...      ...      ...         ...         ...           ...   \n",
       "35272    Tsonga J.W.    245.0      FRA        91.0       188.0  Right-Handed   \n",
       "35273       Copil M.    597.0      ROU        86.0       191.0  Right-Handed   \n",
       "35274      Muller G.   1127.0      LUX        89.0       193.0   Left-Handed   \n",
       "35275   Marchenko I.    305.0      UKR        82.0       185.0  Right-Handed   \n",
       "35276       Souza J.    554.0      BRA        92.0       193.0  Right-Handed   \n",
       "\n",
       "       pl1_professional_time               pl2  pl2_pts pl2_flag  pl2_weight  \\\n",
       "0                        7.0          Simon G.    875.0      FRA        70.0   \n",
       "1                        9.0        Donskoy E.    371.0      RUS        74.0   \n",
       "2                       21.0         Clarke J.    316.0      GBR        83.0   \n",
       "3                       11.0          Kudla D.    496.0      USA        75.0   \n",
       "4                        5.0          Serra F.    780.0      FRA        78.0   \n",
       "...                      ...               ...      ...      ...         ...   \n",
       "35272                   15.0          Simon G.   1280.0      FRA        70.0   \n",
       "35273                   10.0         Bedene A.    815.0      GBR        72.0   \n",
       "35274                   14.0       Wawrinka S.   4050.0      SUI        81.0   \n",
       "35275                    8.0      Matosevic M.    887.0      AUS        86.0   \n",
       "35276                    9.0  Haider-Maurer A.    810.0      AUT        89.0   \n",
       "\n",
       "       pl2_height      pl2_hand  pl2_professional_time          location  \\\n",
       "0           183.0  Right-Handed                    6.0         Rotterdam   \n",
       "1           185.0  Right-Handed                    5.0         Barcelona   \n",
       "2           183.0  Right-Handed                    3.0            London   \n",
       "3           180.0  Right-Handed                    5.0            London   \n",
       "4           180.0  Right-Handed                   10.0         New Haven   \n",
       "...           ...           ...                    ...               ...   \n",
       "35272       183.0  Right-Handed                   17.0       Montpellier   \n",
       "35273       183.0  Right-Handed                   10.0  's-Hertogenbosch   \n",
       "35274       183.0  Right-Handed                   13.0         Rotterdam   \n",
       "35275       193.0  Right-Handed                   11.0        Washington   \n",
       "35276       191.0  Right-Handed                   10.0         Kitzbuhel   \n",
       "\n",
       "                   series    court surface  best_of winner  \n",
       "0      International Gold   Indoor    Hard        3     p2  \n",
       "1                  ATP500  Outdoor    Clay        3     p1  \n",
       "2              Grand Slam  Outdoor   Grass        5     p1  \n",
       "3              Grand Slam  Outdoor   Grass        5     p2  \n",
       "4                  ATP250  Outdoor    Hard        3     p1  \n",
       "...                   ...      ...     ...      ...    ...  \n",
       "35272              ATP250   Indoor    Hard        3     p1  \n",
       "35273              ATP250  Outdoor   Grass        3     p1  \n",
       "35274              ATP500   Indoor    Hard        3     p2  \n",
       "35275              ATP500  Outdoor    Hard        3     p2  \n",
       "35276              ATP250  Outdoor    Clay        3     p2  \n",
       "\n",
       "[35277 rows x 20 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creación de dataset de manera distinta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players_1 = pd.DataFrame()\n",
    "\n",
    "df_players_1[\"pl1\"] = df[\"Winner\"]\n",
    "df_players_1[\"pl1_pts\"] = df[\"WPts\"]\n",
    "df_players_1[\"pl1_flag\"] = df[\"pl1_flag\"]\n",
    "df_players_1[\"pl1_weight\"] = df[\"pl1_weight\"]\n",
    "df_players_1[\"pl1_height\"] = df[\"pl1_height\"]\n",
    "df_players_1[\"pl1_hand\"] = df[\"pl1_hand\"]\n",
    "df_players_1[\"pl1_professional_time\"] = df[\"pl1_professional_time\"]\n",
    "df_players_1[\"pl2\"] = df[\"Loser\"]\n",
    "df_players_1[\"pl2_pts\"] = df[\"LPts\"]\n",
    "df_players_1[\"pl2_flag\"] = df[\"pl2_flag\"]\n",
    "df_players_1[\"pl2_weight\"] = df[\"pl2_weight\"]\n",
    "df_players_1[\"pl2_height\"] = df[\"pl2_height\"]\n",
    "df_players_1[\"pl2_hand\"] = df[\"pl2_hand\"]\n",
    "df_players_1[\"pl2_professional_time\"] = df[\"pl2_professional_time\"]\n",
    "df_players_1[\"location\"] = df[\"Location\"]\n",
    "df_players_1[\"series\"] = df[\"Series\"]\n",
    "df_players_1[\"court\"] = df[\"Court\"]\n",
    "df_players_1[\"surface\"] = df[\"Surface\"]\n",
    "df_players_1[\"best_of\"] = df[\"Best of\"]\n",
    "df_players_1[\"winner\"] = \"p1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players_2 = pd.DataFrame()\n",
    "\n",
    "df_players_2[\"pl1\"] = df[\"Loser\"]\n",
    "df_players_2[\"pl1_pts\"] = df[\"LPts\"]\n",
    "df_players_2[\"pl1_flag\"] = df[\"pl2_flag\"]\n",
    "df_players_2[\"pl1_weight\"] = df[\"pl2_weight\"]\n",
    "df_players_2[\"pl1_height\"] = df[\"pl2_height\"]\n",
    "df_players_2[\"pl1_hand\"] = df[\"pl2_hand\"]\n",
    "df_players_2[\"pl1_professional_time\"] = df[\"pl2_professional_time\"]\n",
    "df_players_2[\"pl2\"] = df[\"Winner\"]\n",
    "df_players_2[\"pl2_pts\"] = df[\"WPts\"]\n",
    "df_players_2[\"pl2_flag\"] = df[\"pl1_flag\"]\n",
    "df_players_2[\"pl2_weight\"] = df[\"pl1_weight\"]\n",
    "df_players_2[\"pl2_height\"] = df[\"pl1_height\"]\n",
    "df_players_2[\"pl2_hand\"] = df[\"pl1_hand\"]\n",
    "df_players_2[\"pl2_professional_time\"] = df[\"pl1_professional_time\"]\n",
    "df_players_2[\"location\"] = df[\"Location\"]\n",
    "df_players_2[\"series\"] = df[\"Series\"]\n",
    "df_players_2[\"court\"] = df[\"Court\"]\n",
    "df_players_2[\"surface\"] = df[\"Surface\"]\n",
    "df_players_2[\"best_of\"] = df[\"Best of\"]\n",
    "df_players_2[\"winner\"] = \"p2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_players = pd.concat([df_players_1, df_players_2])\n",
    "df_all_players = df_all_players.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_players.to_csv(\"data/all_players.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento de modelo de clasificación con grid search sin hacer mucha ingeniería de caracteristicas\n",
    "\n",
    "1. Dividir los datos, usaré 15% para testeo por ahora\n",
    "2. Extraer las variables numericas y categoricas\n",
    "3. Se crean 2 pipelines para imputar y trabajar con variables categoricas y numericas (Imputer, Scaler o one hot encoder)\n",
    "4. Se crea instancia de modelos y también un grid search básico, que no gaste tanta máquina\n",
    "5. Entrenamiento\n",
    "6. Revisión de resultados y mirar cual es el mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#1. __________________________\n",
    "\n",
    "X = df_all_players.drop('winner', axis=1)\n",
    "y = df_all_players['winner']\n",
    "\n",
    "le_winner = LabelEncoder()\n",
    "y = le_winner.fit_transform(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "\n",
    "#2. _____________________________\n",
    "\n",
    "numeric_features = ['pl1_pts', 'pl1_weight', 'pl1_height', 'pl1_professional_time',\n",
    "                    'pl2_pts', 'pl2_weight', 'pl2_height', 'pl2_professional_time']\n",
    "categorical_features = ['pl1_flag', 'pl1_hand', 'pl2_flag', 'pl2_hand', 'location', 'series', 'court', 'surface', 'best_of']\n",
    "\n",
    "#3. _____________________________\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________________________________\n",
      "training model Logistic Regression ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 473, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan 0.70255592        nan 0.69891268        nan 0.69792284]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________________________________\n",
      "training model Random Forest ......................\n",
      "\n",
      "______________________________________________________\n",
      "training model SVM ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________________________________\n",
      "training model XGBoost ......................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "Best Parameters: {'classifier__C': 0.1, 'classifier__penalty': 'l2'}\n",
      "Test AUC: 0.6983\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      3586\n",
      "           1       0.63      0.65      0.64      3470\n",
      "\n",
      "    accuracy                           0.64      7056\n",
      "   macro avg       0.64      0.64      0.64      7056\n",
      "weighted avg       0.64      0.64      0.64      7056\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Best Parameters: {'classifier__max_depth': 20, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200}\n",
      "Test AUC: 0.7154\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65      3586\n",
      "           1       0.64      0.67      0.66      3470\n",
      "\n",
      "    accuracy                           0.66      7056\n",
      "   macro avg       0.66      0.66      0.66      7056\n",
      "weighted avg       0.66      0.66      0.66      7056\n",
      "\n",
      "\n",
      "SVM:\n",
      "Best Parameters: {'classifier__C': 0.1, 'classifier__kernel': 'rbf'}\n",
      "Test AUC: 0.5682\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.57      0.56      3586\n",
      "           1       0.54      0.52      0.53      3470\n",
      "\n",
      "    accuracy                           0.55      7056\n",
      "   macro avg       0.55      0.55      0.55      7056\n",
      "weighted avg       0.55      0.55      0.55      7056\n",
      "\n",
      "\n",
      "XGBoost:\n",
      "Best Parameters: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 100}\n",
      "Test AUC: 0.7144\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65      3586\n",
      "           1       0.64      0.67      0.65      3470\n",
      "\n",
      "    accuracy                           0.65      7056\n",
      "   macro avg       0.65      0.65      0.65      7056\n",
      "weighted avg       0.65      0.65      0.65      7056\n",
      "\n",
      "\n",
      "El mejor modelo es: Random Forest\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#4. Instancias de modelos básicos de ML - Después podemos ensayar con perceptron o con redes _______________________\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ]),\n",
    "    'Random Forest': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ]),\n",
    "    'SVM': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', SVC(probability=True, max_iter=2000))\n",
    "    ]),\n",
    "    'XGBoost': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', XGBClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__penalty': ['l1', 'l2']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['rbf', 'linear']\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [3, 5, 7],\n",
    "        'classifier__learning_rate': [0.01, 0.1]\n",
    "    }\n",
    "}\n",
    "\n",
    "#5. ____________________________________\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(\"\\n______________________________________________________\")\n",
    "    print(f\"training model {name} ......................\")\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    y_prob = grid_search.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    results[name] = {\n",
    "        'Best Parameters': grid_search.best_params_,\n",
    "        'Test AUC': roc_auc_score(y_test, y_prob),\n",
    "        'Classification Report': classification_report(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "#6. _______________________________________\n",
    "\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Best Parameters: {result['Best Parameters']}\")\n",
    "    print(f\"Test AUC: {result['Test AUC']:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(result['Classification Report'])\n",
    "\n",
    "# 11. Identificar el mejor modelo\n",
    "best_model = max(results, key=lambda x: results[x]['Test AUC'])\n",
    "print(f\"\\nEl mejor modelo es: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento de modelo de clasificación con grid search haciendo ingenieria de caracteristicas\n",
    "\n",
    "1. Crearemos nuevas caracteristicas basandonos en el conocimiento del problema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_engineered = df_all_players.copy()\n",
    "\n",
    "#df_feature_engineered.drop(columns=[\"pl1\", \"pl2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuente de este codigo es chatgpt, por lo que está bajo supervisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar datos\n",
    "data = df_feature_engineered\n",
    "\n",
    "# Crear nuevas características\n",
    "data['diff_pts'] = data['pl1_pts'] - data['pl2_pts']\n",
    "data['diff_weight'] = data['pl1_weight'] - data['pl2_weight']\n",
    "data['diff_height'] = data['pl1_height'] - data['pl2_height']\n",
    "data['diff_professional_time'] = data['pl1_professional_time'] - data['pl2_professional_time']\n",
    "data['same_hand'] = (data['pl1_hand'] == data['pl2_hand']).astype(int)\n",
    "\n",
    "# Seleccionar características y variable objetivo\n",
    "features = [\"pl1\", \"pl2\",'pl1_pts', 'pl1_weight', 'pl1_height', 'pl1_professional_time',\n",
    "                    'pl2_pts', 'pl2_weight', 'pl2_height', 'pl2_professional_time','pl1_flag', 'pl1_hand', 'pl2_flag', 'pl2_hand', 'diff_pts', 'diff_weight', 'diff_height', 'diff_professional_time', 'same_hand', 'location', 'series', 'court', 'surface', 'best_of']\n",
    "X = data[features]\n",
    "y = data['winner']\n",
    "\n",
    "le_winner = LabelEncoder()\n",
    "y = le_winner.fit_transform(y)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Transformación de datos\n",
    "numeric_features = ['diff_pts', 'diff_weight', 'diff_height', 'diff_professional_time', 'pl1_pts', 'pl1_weight', 'pl1_height', 'pl1_professional_time',\n",
    "                    'pl2_pts', 'pl2_weight', 'pl2_height', 'pl2_professional_time']\n",
    "categorical_features = [\"pl1\", \"pl2\",'pl1_flag', 'pl1_hand', 'pl2_flag', 'pl2_hand','location', 'series', 'court', 'surface', 'best_of']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Aplicar transformaciones a los datos de entrenamiento\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.6593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      3586\n",
      "           1       0.65      0.67      0.66      3470\n",
      "\n",
      "    accuracy                           0.66      7056\n",
      "   macro avg       0.66      0.66      0.66      7056\n",
      "weighted avg       0.66      0.66      0.66      7056\n",
      "\n",
      "[[2329 1257]\n",
      " [1147 2323]]\n",
      "Gradient Boosting Accuracy: 0.6589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66      3586\n",
      "           1       0.65      0.67      0.66      3470\n",
      "\n",
      "    accuracy                           0.66      7056\n",
      "   macro avg       0.66      0.66      0.66      7056\n",
      "weighted avg       0.66      0.66      0.66      7056\n",
      "\n",
      "[[2334 1252]\n",
      " [1155 2315]]\n",
      "Random Forest CV Accuracy: 0.6593 +/- 0.0044\n",
      "Gradient Boosting CV Accuracy: 0.6578 +/- 0.0035\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Definir modelos\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Hiperparámetros para GridSearchCV\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.05],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# GridSearchCV para Random Forest\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "rf_grid.fit(X_train_processed, y_train)\n",
    "\n",
    "# GridSearchCV para Gradient Boosting\n",
    "gb_grid = GridSearchCV(gb_model, gb_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "gb_grid.fit(X_train_processed, y_train)\n",
    "\n",
    "# Mejor modelo Random Forest\n",
    "best_rf = rf_grid.best_estimator_\n",
    "rf_predictions = best_rf.predict(X_test_processed)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "print(confusion_matrix(y_test, rf_predictions))\n",
    "\n",
    "# Mejor modelo Gradient Boosting\n",
    "best_gb = gb_grid.best_estimator_\n",
    "gb_predictions = best_gb.predict(X_test_processed)\n",
    "gb_accuracy = accuracy_score(y_test, gb_predictions)\n",
    "print(f\"Gradient Boosting Accuracy: {gb_accuracy:.4f}\")\n",
    "print(classification_report(y_test, gb_predictions))\n",
    "print(confusion_matrix(y_test, gb_predictions))\n",
    "\n",
    "# Validación cruzada\n",
    "rf_cv_scores = cross_val_score(best_rf, X_train_processed, y_train, cv=5, scoring='accuracy')\n",
    "gb_cv_scores = cross_val_score(best_gb, X_train_processed, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Random Forest CV Accuracy: {np.mean(rf_cv_scores):.4f} +/- {np.std(rf_cv_scores):.4f}\")\n",
    "print(f\"Gradient Boosting CV Accuracy: {np.mean(gb_cv_scores):.4f} +/- {np.std(gb_cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train SVM model..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Logistic Regression model..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "140 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1204, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan 0.64816984 0.64820528 0.641083   0.64129562 0.64133105\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.63927581 0.63927581 0.63736239 0.63764587 0.63761043\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.63626391 0.63626391 0.63583866 0.63590959 0.63587415\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.63605131 0.63605132 0.63615757 0.63598044 0.63601588\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train XG Boost model..........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.59      3586\n",
      "           1       0.58      0.60      0.59      3470\n",
      "\n",
      "    accuracy                           0.59      7056\n",
      "   macro avg       0.59      0.59      0.59      7056\n",
      "weighted avg       0.59      0.59      0.59      7056\n",
      "\n",
      "[[2098 1488]\n",
      " [1379 2091]]\n",
      "Logistic Regression Accuracy: 0.6460\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      3586\n",
      "           1       0.64      0.66      0.65      3470\n",
      "\n",
      "    accuracy                           0.65      7056\n",
      "   macro avg       0.65      0.65      0.65      7056\n",
      "weighted avg       0.65      0.65      0.65      7056\n",
      "\n",
      "[[2278 1308]\n",
      " [1190 2280]]\n",
      "XGBoost Accuracy: 0.6555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65      3586\n",
      "           1       0.64      0.68      0.66      3470\n",
      "\n",
      "    accuracy                           0.66      7056\n",
      "   macro avg       0.66      0.66      0.66      7056\n",
      "weighted avg       0.66      0.66      0.66      7056\n",
      "\n",
      "[[2274 1312]\n",
      " [1119 2351]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM CV Accuracy: 0.5960 +/- 0.0046\n",
      "Logistic Regression CV Accuracy: 0.6482 +/- 0.0072\n",
      "XGBoost CV Accuracy: 0.6550 +/- 0.0061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Definir modelos\n",
    "svm_model = SVC(random_state=42, max_iter=2000)\n",
    "logreg_model = LogisticRegression(random_state=42, max_iter=10000)\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Hiperparámetros para GridSearchCV\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "logreg_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver': ['lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.05],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# GridSearchCV para SVM\n",
    "print(\"Train SVM model..........................\")\n",
    "svm_grid = GridSearchCV(svm_model, svm_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "svm_grid.fit(X_train_processed, y_train)\n",
    "\n",
    "# GridSearchCV para Logistic Regression\n",
    "print(\"Train Logistic Regression model..........................\")\n",
    "logreg_grid = GridSearchCV(logreg_model, logreg_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "logreg_grid.fit(X_train_processed, y_train)\n",
    "\n",
    "# GridSearchCV para XGBoost\n",
    "print(\"Train XG Boost model..........................\")\n",
    "xgb_grid = GridSearchCV(xgb_model, xgb_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "xgb_grid.fit(X_train_processed, y_train)\n",
    "\n",
    "# Mejor modelo SVM\n",
    "best_svm = svm_grid.best_estimator_\n",
    "svm_predictions = best_svm.predict(X_test_processed)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(classification_report(y_test, svm_predictions))\n",
    "print(confusion_matrix(y_test, svm_predictions))\n",
    "\n",
    "# Mejor modelo Logistic Regression\n",
    "best_logreg = logreg_grid.best_estimator_\n",
    "logreg_predictions = best_logreg.predict(X_test_processed)\n",
    "logreg_accuracy = accuracy_score(y_test, logreg_predictions)\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy:.4f}\")\n",
    "print(classification_report(y_test, logreg_predictions))\n",
    "print(confusion_matrix(y_test, logreg_predictions))\n",
    "\n",
    "# Mejor modelo XGBoost\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "xgb_predictions = best_xgb.predict(X_test_processed)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
    "print(f\"XGBoost Accuracy: {xgb_accuracy:.4f}\")\n",
    "print(classification_report(y_test, xgb_predictions))\n",
    "print(confusion_matrix(y_test, xgb_predictions))\n",
    "\n",
    "# Validación cruzada\n",
    "svm_cv_scores = cross_val_score(best_svm, X_train_processed, y_train, cv=5, scoring='accuracy')\n",
    "logreg_cv_scores = cross_val_score(best_logreg, X_train_processed, y_train, cv=5, scoring='accuracy')\n",
    "xgb_cv_scores = cross_val_score(best_xgb, X_train_processed, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"SVM CV Accuracy: {np.mean(svm_cv_scores):.4f} +/- {np.std(svm_cv_scores):.4f}\")\n",
    "print(f\"Logistic Regression CV Accuracy: {np.mean(logreg_cv_scores):.4f} +/- {np.std(logreg_cv_scores):.4f}\")\n",
    "print(f\"XGBoost CV Accuracy: {np.mean(xgb_cv_scores):.4f} +/- {np.std(xgb_cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\dev\\tennis_bet\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5130 - loss: 0.8614 - val_accuracy: 0.6129 - val_loss: 0.6576\n",
      "Epoch 2/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5793 - loss: 0.6709 - val_accuracy: 0.6396 - val_loss: 0.6285\n",
      "Epoch 3/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6457 - loss: 0.6263 - val_accuracy: 0.6580 - val_loss: 0.6154\n",
      "Epoch 4/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6653 - loss: 0.6078 - val_accuracy: 0.6568 - val_loss: 0.6154\n",
      "Epoch 5/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6786 - loss: 0.5935 - val_accuracy: 0.6568 - val_loss: 0.6154\n",
      "Epoch 6/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6949 - loss: 0.5813 - val_accuracy: 0.6578 - val_loss: 0.6172\n",
      "Epoch 7/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6957 - loss: 0.5773 - val_accuracy: 0.6601 - val_loss: 0.6183\n",
      "Epoch 8/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7073 - loss: 0.5655 - val_accuracy: 0.6568 - val_loss: 0.6178\n",
      "Epoch 9/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7275 - loss: 0.5470 - val_accuracy: 0.6538 - val_loss: 0.6249\n",
      "Epoch 10/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7252 - loss: 0.5452 - val_accuracy: 0.6620 - val_loss: 0.6320\n",
      "Epoch 11/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.5345 - val_accuracy: 0.6573 - val_loss: 0.6402\n",
      "Epoch 12/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7448 - loss: 0.5199 - val_accuracy: 0.6611 - val_loss: 0.6416\n",
      "Epoch 13/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7563 - loss: 0.5024 - val_accuracy: 0.6533 - val_loss: 0.6449\n",
      "Epoch 14/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7650 - loss: 0.4923 - val_accuracy: 0.6538 - val_loss: 0.6467\n",
      "Epoch 15/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7723 - loss: 0.4825 - val_accuracy: 0.6538 - val_loss: 0.6608\n",
      "Epoch 16/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.4759 - val_accuracy: 0.6547 - val_loss: 0.6563\n",
      "Epoch 17/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7843 - loss: 0.4546 - val_accuracy: 0.6552 - val_loss: 0.6742\n",
      "Epoch 18/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.4472 - val_accuracy: 0.6512 - val_loss: 0.6775\n",
      "Epoch 19/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8001 - loss: 0.4365 - val_accuracy: 0.6514 - val_loss: 0.6717\n",
      "Epoch 20/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8060 - loss: 0.4285 - val_accuracy: 0.6474 - val_loss: 0.6769\n",
      "Epoch 21/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.4256 - val_accuracy: 0.6504 - val_loss: 0.6979\n",
      "Epoch 22/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8055 - loss: 0.4227 - val_accuracy: 0.6519 - val_loss: 0.7006\n",
      "Epoch 23/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8170 - loss: 0.4038 - val_accuracy: 0.6504 - val_loss: 0.7077\n",
      "Epoch 24/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8259 - loss: 0.3937 - val_accuracy: 0.6457 - val_loss: 0.7133\n",
      "Epoch 25/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8267 - loss: 0.3962 - val_accuracy: 0.6488 - val_loss: 0.7131\n",
      "Epoch 26/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8334 - loss: 0.3775 - val_accuracy: 0.6462 - val_loss: 0.7211\n",
      "Epoch 27/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.3708 - val_accuracy: 0.6507 - val_loss: 0.7422\n",
      "Epoch 28/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3666 - val_accuracy: 0.6488 - val_loss: 0.7244\n",
      "Epoch 29/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8411 - loss: 0.3676 - val_accuracy: 0.6469 - val_loss: 0.7394\n",
      "Epoch 30/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8449 - loss: 0.3569 - val_accuracy: 0.6415 - val_loss: 0.7540\n",
      "Epoch 31/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8447 - loss: 0.3525 - val_accuracy: 0.6448 - val_loss: 0.7597\n",
      "Epoch 32/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8452 - loss: 0.3563 - val_accuracy: 0.6403 - val_loss: 0.7772\n",
      "Epoch 33/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8454 - loss: 0.3476 - val_accuracy: 0.6476 - val_loss: 0.7526\n",
      "Epoch 34/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8485 - loss: 0.3455 - val_accuracy: 0.6438 - val_loss: 0.7798\n",
      "Epoch 35/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8545 - loss: 0.3363 - val_accuracy: 0.6427 - val_loss: 0.7696\n",
      "Epoch 36/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8504 - loss: 0.3420 - val_accuracy: 0.6424 - val_loss: 0.7730\n",
      "Epoch 37/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8563 - loss: 0.3385 - val_accuracy: 0.6372 - val_loss: 0.7795\n",
      "Epoch 38/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8564 - loss: 0.3326 - val_accuracy: 0.6384 - val_loss: 0.7895\n",
      "Epoch 39/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8606 - loss: 0.3212 - val_accuracy: 0.6365 - val_loss: 0.8153\n",
      "Epoch 40/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.3191 - val_accuracy: 0.6398 - val_loss: 0.8043\n",
      "Epoch 41/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8620 - loss: 0.3250 - val_accuracy: 0.6379 - val_loss: 0.8172\n",
      "Epoch 42/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8644 - loss: 0.3170 - val_accuracy: 0.6405 - val_loss: 0.8060\n",
      "Epoch 43/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8708 - loss: 0.3087 - val_accuracy: 0.6372 - val_loss: 0.7997\n",
      "Epoch 44/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8633 - loss: 0.3108 - val_accuracy: 0.6384 - val_loss: 0.8181\n",
      "Epoch 45/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8717 - loss: 0.3062 - val_accuracy: 0.6344 - val_loss: 0.8209\n",
      "Epoch 46/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8691 - loss: 0.3071 - val_accuracy: 0.6337 - val_loss: 0.8272\n",
      "Epoch 47/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.3067 - val_accuracy: 0.6389 - val_loss: 0.8190\n",
      "Epoch 48/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8715 - loss: 0.3031 - val_accuracy: 0.6370 - val_loss: 0.8173\n",
      "Epoch 49/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8706 - loss: 0.3037 - val_accuracy: 0.6464 - val_loss: 0.8374\n",
      "Epoch 50/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8735 - loss: 0.2956 - val_accuracy: 0.6401 - val_loss: 0.8364\n",
      "Epoch 51/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8785 - loss: 0.2910 - val_accuracy: 0.6370 - val_loss: 0.8411\n",
      "Epoch 52/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8790 - loss: 0.2919 - val_accuracy: 0.6370 - val_loss: 0.8124\n",
      "Epoch 53/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.2869 - val_accuracy: 0.6363 - val_loss: 0.8459\n",
      "Epoch 54/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8841 - loss: 0.2807 - val_accuracy: 0.6412 - val_loss: 0.8211\n",
      "Epoch 55/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8776 - loss: 0.2878 - val_accuracy: 0.6431 - val_loss: 0.8289\n",
      "Epoch 56/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8786 - loss: 0.2867 - val_accuracy: 0.6360 - val_loss: 0.8409\n",
      "Epoch 57/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.2786 - val_accuracy: 0.6346 - val_loss: 0.8498\n",
      "Epoch 58/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8811 - loss: 0.2845 - val_accuracy: 0.6349 - val_loss: 0.8588\n",
      "Epoch 59/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8872 - loss: 0.2734 - val_accuracy: 0.6368 - val_loss: 0.8545\n",
      "Epoch 60/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.2777 - val_accuracy: 0.6325 - val_loss: 0.8826\n",
      "Epoch 61/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8866 - loss: 0.2731 - val_accuracy: 0.6372 - val_loss: 0.8404\n",
      "Epoch 62/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.2831 - val_accuracy: 0.6332 - val_loss: 0.8704\n",
      "Epoch 63/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8841 - loss: 0.2720 - val_accuracy: 0.6356 - val_loss: 0.8870\n",
      "Epoch 64/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.2668 - val_accuracy: 0.6365 - val_loss: 0.8450\n",
      "Epoch 65/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8886 - loss: 0.2665 - val_accuracy: 0.6391 - val_loss: 0.8644\n",
      "Epoch 66/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2711 - val_accuracy: 0.6419 - val_loss: 0.8857\n",
      "Epoch 67/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8934 - loss: 0.2596 - val_accuracy: 0.6363 - val_loss: 0.8662\n",
      "Epoch 68/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.2662 - val_accuracy: 0.6403 - val_loss: 0.8815\n",
      "Epoch 69/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8954 - loss: 0.2641 - val_accuracy: 0.6396 - val_loss: 0.8755\n",
      "Epoch 70/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8912 - loss: 0.2630 - val_accuracy: 0.6403 - val_loss: 0.8457\n",
      "Epoch 71/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.2688 - val_accuracy: 0.6427 - val_loss: 0.9256\n",
      "Epoch 72/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8921 - loss: 0.2626 - val_accuracy: 0.6401 - val_loss: 0.8785\n",
      "Epoch 73/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8943 - loss: 0.2583 - val_accuracy: 0.6405 - val_loss: 0.8992\n",
      "Epoch 74/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.2596 - val_accuracy: 0.6377 - val_loss: 0.8905\n",
      "Epoch 75/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.2585 - val_accuracy: 0.6405 - val_loss: 0.9200\n",
      "Epoch 76/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.2623 - val_accuracy: 0.6346 - val_loss: 0.8991\n",
      "Epoch 77/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8912 - loss: 0.2658 - val_accuracy: 0.6398 - val_loss: 0.9004\n",
      "Epoch 78/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2571 - val_accuracy: 0.6377 - val_loss: 0.8967\n",
      "Epoch 79/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8970 - loss: 0.2482 - val_accuracy: 0.6372 - val_loss: 0.9120\n",
      "Epoch 80/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8985 - loss: 0.2482 - val_accuracy: 0.6379 - val_loss: 0.8935\n",
      "Epoch 81/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8886 - loss: 0.2655 - val_accuracy: 0.6344 - val_loss: 0.9060\n",
      "Epoch 82/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9014 - loss: 0.2479 - val_accuracy: 0.6386 - val_loss: 0.9068\n",
      "Epoch 83/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.2527 - val_accuracy: 0.6346 - val_loss: 0.9293\n",
      "Epoch 84/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8915 - loss: 0.2609 - val_accuracy: 0.6344 - val_loss: 0.9245\n",
      "Epoch 85/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8941 - loss: 0.2520 - val_accuracy: 0.6351 - val_loss: 0.9530\n",
      "Epoch 86/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8965 - loss: 0.2544 - val_accuracy: 0.6396 - val_loss: 0.9035\n",
      "Epoch 87/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9032 - loss: 0.2384 - val_accuracy: 0.6443 - val_loss: 0.9169\n",
      "Epoch 88/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.2561 - val_accuracy: 0.6412 - val_loss: 0.9154\n",
      "Epoch 89/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8954 - loss: 0.2583 - val_accuracy: 0.6417 - val_loss: 0.9098\n",
      "Epoch 90/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8996 - loss: 0.2486 - val_accuracy: 0.6386 - val_loss: 0.8958\n",
      "Epoch 91/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.2511 - val_accuracy: 0.6358 - val_loss: 0.9034\n",
      "Epoch 92/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.2486 - val_accuracy: 0.6375 - val_loss: 0.9300\n",
      "Epoch 93/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9065 - loss: 0.2360 - val_accuracy: 0.6389 - val_loss: 0.9287\n",
      "Epoch 94/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9015 - loss: 0.2444 - val_accuracy: 0.6356 - val_loss: 0.8988\n",
      "Epoch 95/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9057 - loss: 0.2374 - val_accuracy: 0.6384 - val_loss: 0.9456\n",
      "Epoch 96/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9048 - loss: 0.2374 - val_accuracy: 0.6412 - val_loss: 0.9322\n",
      "Epoch 97/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9056 - loss: 0.2331 - val_accuracy: 0.6396 - val_loss: 0.9303\n",
      "Epoch 98/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.2369 - val_accuracy: 0.6375 - val_loss: 0.9482\n",
      "Epoch 99/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9039 - loss: 0.2410 - val_accuracy: 0.6334 - val_loss: 0.9671\n",
      "Epoch 100/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8994 - loss: 0.2441 - val_accuracy: 0.6417 - val_loss: 0.8968\n",
      "Epoch 101/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 0.2390 - val_accuracy: 0.6384 - val_loss: 0.9266\n",
      "Epoch 102/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.2358 - val_accuracy: 0.6393 - val_loss: 0.9583\n",
      "Epoch 103/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.2406 - val_accuracy: 0.6391 - val_loss: 0.9218\n",
      "Epoch 104/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9065 - loss: 0.2331 - val_accuracy: 0.6419 - val_loss: 0.9597\n",
      "Epoch 105/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9023 - loss: 0.2381 - val_accuracy: 0.6436 - val_loss: 0.9197\n",
      "Epoch 106/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9029 - loss: 0.2368 - val_accuracy: 0.6384 - val_loss: 0.9411\n",
      "Epoch 107/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.2251 - val_accuracy: 0.6403 - val_loss: 0.9367\n",
      "Epoch 108/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9042 - loss: 0.2374 - val_accuracy: 0.6415 - val_loss: 0.9382\n",
      "Epoch 109/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 0.2383 - val_accuracy: 0.6419 - val_loss: 0.9367\n",
      "Epoch 110/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9085 - loss: 0.2312 - val_accuracy: 0.6408 - val_loss: 0.8990\n",
      "Epoch 111/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9077 - loss: 0.2314 - val_accuracy: 0.6469 - val_loss: 0.9495\n",
      "Epoch 112/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.2282 - val_accuracy: 0.6471 - val_loss: 0.9116\n",
      "Epoch 113/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9012 - loss: 0.2382 - val_accuracy: 0.6450 - val_loss: 0.9372\n",
      "Epoch 114/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2245 - val_accuracy: 0.6455 - val_loss: 0.9386\n",
      "Epoch 115/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.2270 - val_accuracy: 0.6453 - val_loss: 0.9641\n",
      "Epoch 116/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.2309 - val_accuracy: 0.6507 - val_loss: 0.9308\n",
      "Epoch 117/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9028 - loss: 0.2334 - val_accuracy: 0.6476 - val_loss: 0.9257\n",
      "Epoch 118/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.2234 - val_accuracy: 0.6460 - val_loss: 0.9431\n",
      "Epoch 119/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9104 - loss: 0.2249 - val_accuracy: 0.6457 - val_loss: 0.9121\n",
      "Epoch 120/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.2326 - val_accuracy: 0.6436 - val_loss: 0.9490\n",
      "Epoch 121/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9076 - loss: 0.2332 - val_accuracy: 0.6519 - val_loss: 0.9116\n",
      "Epoch 122/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2306 - val_accuracy: 0.6469 - val_loss: 0.9343\n",
      "Epoch 123/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9104 - loss: 0.2212 - val_accuracy: 0.6462 - val_loss: 0.9493\n",
      "Epoch 124/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2202 - val_accuracy: 0.6502 - val_loss: 0.9540\n",
      "Epoch 125/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9078 - loss: 0.2303 - val_accuracy: 0.6469 - val_loss: 0.9372\n",
      "Epoch 126/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2260 - val_accuracy: 0.6450 - val_loss: 0.9547\n",
      "Epoch 127/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.2233 - val_accuracy: 0.6486 - val_loss: 0.9439\n",
      "Epoch 128/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9069 - loss: 0.2306 - val_accuracy: 0.6460 - val_loss: 0.9474\n",
      "Epoch 129/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.2260 - val_accuracy: 0.6486 - val_loss: 0.9384\n",
      "Epoch 130/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.2308 - val_accuracy: 0.6434 - val_loss: 0.9549\n",
      "Epoch 131/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9085 - loss: 0.2219 - val_accuracy: 0.6497 - val_loss: 0.9325\n",
      "Epoch 132/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9038 - loss: 0.2323 - val_accuracy: 0.6460 - val_loss: 0.9705\n",
      "Epoch 133/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.2314 - val_accuracy: 0.6417 - val_loss: 0.9511\n",
      "Epoch 134/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.2234 - val_accuracy: 0.6391 - val_loss: 0.9629\n",
      "Epoch 135/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9103 - loss: 0.2277 - val_accuracy: 0.6372 - val_loss: 0.9701\n",
      "Epoch 136/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.2266 - val_accuracy: 0.6460 - val_loss: 0.9573\n",
      "Epoch 137/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2196 - val_accuracy: 0.6431 - val_loss: 0.9703\n",
      "Epoch 138/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2199 - val_accuracy: 0.6453 - val_loss: 1.0012\n",
      "Epoch 139/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9082 - loss: 0.2305 - val_accuracy: 0.6486 - val_loss: 0.9813\n",
      "Epoch 140/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9095 - loss: 0.2247 - val_accuracy: 0.6469 - val_loss: 0.9725\n",
      "Epoch 141/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.2241 - val_accuracy: 0.6412 - val_loss: 0.9868\n",
      "Epoch 142/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2190 - val_accuracy: 0.6497 - val_loss: 0.9766\n",
      "Epoch 143/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2232 - val_accuracy: 0.6500 - val_loss: 0.9947\n",
      "Epoch 144/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.2271 - val_accuracy: 0.6469 - val_loss: 1.0193\n",
      "Epoch 145/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.2185 - val_accuracy: 0.6486 - val_loss: 0.9853\n",
      "Epoch 146/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.2159 - val_accuracy: 0.6490 - val_loss: 0.9755\n",
      "Epoch 147/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2207 - val_accuracy: 0.6448 - val_loss: 0.9657\n",
      "Epoch 148/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.2148 - val_accuracy: 0.6493 - val_loss: 0.9593\n",
      "Epoch 149/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9093 - loss: 0.2231 - val_accuracy: 0.6441 - val_loss: 0.9657\n",
      "Epoch 150/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2170 - val_accuracy: 0.6424 - val_loss: 0.9541\n",
      "Epoch 151/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.2239 - val_accuracy: 0.6443 - val_loss: 0.9561\n",
      "Epoch 152/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.2251 - val_accuracy: 0.6460 - val_loss: 0.9868\n",
      "Epoch 153/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.2229 - val_accuracy: 0.6500 - val_loss: 0.9891\n",
      "Epoch 154/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2169 - val_accuracy: 0.6476 - val_loss: 0.9632\n",
      "Epoch 155/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.2136 - val_accuracy: 0.6476 - val_loss: 0.9945\n",
      "Epoch 156/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9158 - loss: 0.2100 - val_accuracy: 0.6460 - val_loss: 0.9700\n",
      "Epoch 157/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.2171 - val_accuracy: 0.6460 - val_loss: 1.0174\n",
      "Epoch 158/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.2249 - val_accuracy: 0.6453 - val_loss: 0.9745\n",
      "Epoch 159/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.2186 - val_accuracy: 0.6516 - val_loss: 0.9705\n",
      "Epoch 160/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9121 - loss: 0.2190 - val_accuracy: 0.6500 - val_loss: 0.9683\n",
      "Epoch 161/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.2079 - val_accuracy: 0.6471 - val_loss: 0.9882\n",
      "Epoch 162/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2069 - val_accuracy: 0.6464 - val_loss: 0.9638\n",
      "Epoch 163/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2105 - val_accuracy: 0.6497 - val_loss: 1.0020\n",
      "Epoch 164/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.2137 - val_accuracy: 0.6502 - val_loss: 0.9782\n",
      "Epoch 165/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2115 - val_accuracy: 0.6467 - val_loss: 0.9720\n",
      "Epoch 166/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2127 - val_accuracy: 0.6469 - val_loss: 1.0192\n",
      "Epoch 167/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9143 - loss: 0.2172 - val_accuracy: 0.6502 - val_loss: 1.0328\n",
      "Epoch 168/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2167 - val_accuracy: 0.6438 - val_loss: 0.9879\n",
      "Epoch 169/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2207 - val_accuracy: 0.6431 - val_loss: 0.9843\n",
      "Epoch 170/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.2104 - val_accuracy: 0.6474 - val_loss: 0.9507\n",
      "Epoch 171/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.2206 - val_accuracy: 0.6476 - val_loss: 0.9970\n",
      "Epoch 172/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2148 - val_accuracy: 0.6476 - val_loss: 1.0111\n",
      "Epoch 173/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2060 - val_accuracy: 0.6500 - val_loss: 0.9768\n",
      "Epoch 174/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2076 - val_accuracy: 0.6469 - val_loss: 0.9982\n",
      "Epoch 175/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9158 - loss: 0.2111 - val_accuracy: 0.6521 - val_loss: 0.9901\n",
      "Epoch 176/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2170 - val_accuracy: 0.6542 - val_loss: 1.0209\n",
      "Epoch 177/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9158 - loss: 0.2146 - val_accuracy: 0.6547 - val_loss: 1.0194\n",
      "Epoch 178/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2191 - val_accuracy: 0.6528 - val_loss: 0.9856\n",
      "Epoch 179/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2148 - val_accuracy: 0.6516 - val_loss: 0.9934\n",
      "Epoch 180/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2159 - val_accuracy: 0.6549 - val_loss: 1.0020\n",
      "Epoch 181/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2153 - val_accuracy: 0.6526 - val_loss: 1.0564\n",
      "Epoch 182/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.2118 - val_accuracy: 0.6512 - val_loss: 1.0164\n",
      "Epoch 183/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.2025 - val_accuracy: 0.6474 - val_loss: 1.0074\n",
      "Epoch 184/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9143 - loss: 0.2123 - val_accuracy: 0.6514 - val_loss: 0.9904\n",
      "Epoch 185/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9202 - loss: 0.2039 - val_accuracy: 0.6523 - val_loss: 1.0064\n",
      "Epoch 186/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2011 - val_accuracy: 0.6495 - val_loss: 1.0100\n",
      "Epoch 187/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2006 - val_accuracy: 0.6516 - val_loss: 1.0610\n",
      "Epoch 188/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.2100 - val_accuracy: 0.6476 - val_loss: 1.0903\n",
      "Epoch 189/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2069 - val_accuracy: 0.6471 - val_loss: 1.0219\n",
      "Epoch 190/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2154 - val_accuracy: 0.6481 - val_loss: 1.0483\n",
      "Epoch 191/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.2116 - val_accuracy: 0.6519 - val_loss: 1.0072\n",
      "Epoch 192/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2063 - val_accuracy: 0.6483 - val_loss: 1.0173\n",
      "Epoch 193/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.2074 - val_accuracy: 0.6474 - val_loss: 1.0544\n",
      "Epoch 194/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2107 - val_accuracy: 0.6427 - val_loss: 0.9378\n",
      "Epoch 195/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2019 - val_accuracy: 0.6455 - val_loss: 1.0364\n",
      "Epoch 196/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2076 - val_accuracy: 0.6462 - val_loss: 1.0392\n",
      "Epoch 197/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2090 - val_accuracy: 0.6403 - val_loss: 1.0007\n",
      "Epoch 198/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2059 - val_accuracy: 0.6460 - val_loss: 1.0477\n",
      "Epoch 199/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.2011 - val_accuracy: 0.6412 - val_loss: 1.0316\n",
      "Epoch 200/200\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2136 - val_accuracy: 0.6412 - val_loss: 1.0437\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Neural Network Accuracy: 0.6149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61      3586\n",
      "           1       0.60      0.63      0.62      3470\n",
      "\n",
      "    accuracy                           0.61      7056\n",
      "   macro avg       0.62      0.62      0.61      7056\n",
      "weighted avg       0.62      0.61      0.61      7056\n",
      "\n",
      "[[2166 1420]\n",
      " [1297 2173]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import scipy.sparse\n",
    "\n",
    "# Verificar si los datos son dispersos\n",
    "if scipy.sparse.issparse(X_train_processed):\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "else:\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "# Escalar los datos\n",
    "X_train_scaled = scaler.fit_transform(X_train_processed)\n",
    "X_test_scaled = scaler.transform(X_test_processed)\n",
    "\n",
    "# Definir la arquitectura del modelo\n",
    "def create_nn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Sigmoid para clasificación binaria\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_advanced_nn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Sigmoid para clasificación binaria\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Crear el modelo\n",
    "nn_model = create_advanced_nn_model()\n",
    "\n",
    "# Entrenar el modelo\n",
    "nn_model.fit(X_train_scaled, y_train, epochs=200, batch_size=32, verbose=1, validation_split=0.15)\n",
    "\n",
    "# Evaluar el modelo\n",
    "nn_predictions = (nn_model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "nn_accuracy = accuracy_score(y_test, nn_predictions)\n",
    "print(f\"Neural Network Accuracy: {nn_accuracy:.4f}\")\n",
    "print(classification_report(y_test, nn_predictions))\n",
    "print(confusion_matrix(y_test, nn_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Accuracy: 0.6633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66      3586\n",
      "           1       0.65      0.68      0.66      3470\n",
      "\n",
      "    accuracy                           0.66      7056\n",
      "   macro avg       0.66      0.66      0.66      7056\n",
      "weighted avg       0.66      0.66      0.66      7056\n",
      "\n",
      "[[2333 1253]\n",
      " [1123 2347]]\n",
      "CatBoost CV Accuracy: 0.6598 +/- 0.0031\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Verificar si los datos son dispersos\n",
    "if scipy.sparse.issparse(X_train_processed):\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "else:\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "# Escalar los datos\n",
    "X_train_scaled = scaler.fit_transform(X_train_processed)\n",
    "X_test_scaled = scaler.transform(X_test_processed)\n",
    "\n",
    "# Definir el modelo de CatBoost\n",
    "catboost_model = CatBoostClassifier(verbose=0)\n",
    "\n",
    "# Definir los hiperparámetros para GridSearchCV\n",
    "param_grid = {\n",
    "    'iterations': [100, 200, 300],\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(estimator=catboost_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Resultados del mejor modelo\n",
    "best_model = grid_result.best_estimator_\n",
    "catboost_predictions = best_model.predict(X_test_scaled)\n",
    "catboost_accuracy = accuracy_score(y_test, catboost_predictions)\n",
    "print(f\"CatBoost Accuracy: {catboost_accuracy:.4f}\")\n",
    "print(classification_report(y_test, catboost_predictions))\n",
    "print(confusion_matrix(y_test, catboost_predictions))\n",
    "\n",
    "# Validación cruzada\n",
    "catboost_cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=3, scoring='accuracy')\n",
    "print(f\"CatBoost CV Accuracy: {np.mean(catboost_cv_scores):.4f} +/- {np.std(catboost_cv_scores):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
